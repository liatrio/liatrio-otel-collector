# azuredevops Receiver

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [development]: metrics   |
| Distributions | [liatrio] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Areceiver%2Fazuredevops%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Areceiver%2Fazuredevops) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Areceiver%2Fazuredevops%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Areceiver%2Fazuredevops) |
| Code coverage | [![codecov](https://codecov.io/github/open-telemetry/opentelemetry-collector-contrib/graph/main/badge.svg?component=receiver_azuredevops)](https://app.codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/tree/main/?components%5B0%5D=receiver_azuredevops&displayType=list) |

[development]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#development
[liatrio]: 
<!-- end autogenerated section -->

The azuredevops receiver receives data from [Azure DevOps](https://dev.azure.com/). As a
starting point it scrapes metrics from projects but will be extended to
include traces and logs.

The current default set of metrics can be found in
[documentation.md](./documentation.md).

These metrics can be used as leading indicators ([capabilities][doracap])
to the [DORA][dorafour] metrics; helping provide insight into modern-day
engineering practices.

[doracap]: https://dora.dev/capabilities/
[dorafour]: https://dora.dev/guides/dora-metrics-four-keys/

## Getting Started

The collection interval is common to all scrapers and is set to 30 seconds by default.

> Note: Generally speaking, if the vendor allows for anonymous API calls, then you
> won't have to configure any authentication, but you may only see public repositories
> and organizations. You may run into significantly more rate limiting.

```yaml
azuredevops:
    initial_delay: <duration>
    collection_interval: <duration> #default = 30s recommended 300s
    scrapers:
        azuredevops:
        ...
```

A more complete example using the azuredevops scrapers with authentication is as follows:

```yaml
extensions:
    bearertokenauth/azuredevops:
        token: ${env:GL_PAT}

receivers:
    azuredevops:
        initial_delay: 1s
        collection_interval: 60s
        scrapers:
            azuredevops:
                metrics:
                    vcs.repository.contributor.count:
                        enabled: true
                azuredevops_org: myfancyorg
                search_query: "org:myfancyorg topic:o11yalltheway" #Recommended optional query override, defaults to "{org,user}:<azuredevops_org>"
                limit_merge_requests: 30 #Limit querying merged MRs to the last 30 days, defaults to querying all historical merged MRs
                endpoint: "https://selfmanagedenterpriseserver.com"
                auth:
                    authenticator: bearertokenauth/azuredevops
service:
    extensions: [bearertokenauth/azuredevops]
    pipelines:
        metrics:
            receivers: [..., azuredevops]
            processors: []
            exporters: [...]
```

A Grafana Dashboard exists on the marketplace for metrics from this receiver
and can be found
[here](https://grafana.com/grafana/dashboards/20976-engineering-effectiveness-metrics/).

## Scraping

> Important:
> * The azuredevops scraper does not emit metrics for refs that have not had
>   changes since creation from the default ref (trunk).
> * Due to Azure DevOps API limitations, it is possible for the ref time metric to
>   change when rebases occur, recreating the commits with new timestamps.


<!-- TODO: Combine this documentation once the scraper code is restructured due scope change -->
