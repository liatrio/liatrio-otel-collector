# Git Provider Receiver

<!-- markdownlint-disable -->
<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [development]: metrics   |
| Distributions | [liatrio] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Areceiver%2Fgitprovider%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Areceiver%2Fgitprovider) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Areceiver%2Fgitprovider%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Areceiver%2Fgitprovider) |

[development]: https://github.com/open-telemetry/opentelemetry-collector#development
[liatrio]: 
<!-- end autogenerated section -->
<!-- markdownlint-enable -->

The Git Provider receiver scrapes data from Git vendors.

As a starting point, this receiver can infer many of the same core git metrics
across vendors, while being able to receive additional data specific to vendors.

The current default set of metrics common across all vendors can be found in [documentation.md](./documentation.md).

These default metrics can be used as leading indicators to the DORA metrics;
helping provide insight into modern-day engineering practices.

## Getting Started

The collection interval is common to all scrapers and is set to 30 seconds by default.

> Note: Generally speaking, if the vendor allows for anonymous API calls, then you
> won't have to configure any authentication, but you may only see public repositories
> and organizations. You may run into significantly more rate limiting.

```yaml
gitprovider:
    collection_interval: <duration> #default = 30s recommended 300s
    scrapers:
        <scraper1>:
        <scraper2>:
        ...
```

A more complete example using the GitHub & GitLab scrapers with authentication is as follows:

```yaml
extensions:
    bearertokenauth/github:
        token: ${env:GH_PAT}
    bearertokenauth/gitlab:
        token: ${env:GL_PAT}

receivers:
    gitprovider:
        initial_delay: 1s
        collection_interval: 300s
        scrapers:
            # GitHub Scraper settings
            github:
                metrics:
                    git.repository.contributor.count:
                        enabled: true
                    git.repository.cve.count:
                        enabled: true
                github_org: myfancyorg
                search_query: "org:myfancyorg topic:o11yalltheway" #Recommended optional query override, defaults to "{org,user}:<github_org>"
                endpoint: "https://selfmanagedenterpriseserver.com"
                auth:
                    authenticator: bearertokenauth/github
            # GitLab scraper settings
            gitlab:
                metrics:
                    git.repository.contributor.count:
                        enabled: true
                    git.repository.cve.count:
                        enabled: true
                gitlab_org: myfancyorg
                search_topic: "o11yalltheway"
                auth:
                    authenticator: bearertokenauth/gitlab

service:
    extensions: [bearertokenauth/github, bearertokenauth/gitlab]
    pipelines:
        metrics:
            receivers: [..., gitprovider]
            processors: []
            exporters: [...]
```

This receiver is developed upstream in the [liatrio-otel-collector distribution](https://github.com/liatrio/liatrio-otel-collector)
where a quick start exists with an [example config](https://github.com/liatrio/liatrio-otel-collector/blob/main/config/config.yaml)

A Grafana Dashboard exists on the marketplace for this receiver and can be
found [here](https://grafana.com/grafana/dashboards/20976-engineering-effectiveness-metrics/).

The available scrapers are:
| Scraper  | Description             |
|----------|-------------------------|
| [github] | Git Metrics from [GitHub](https://github.com/) |
| [gitlab] | Git Metrics from [GitLab](https://gitlab.com)  |

## GitHub Metrics

The current metrics available via scraping from GitHub are:

- [x] Repository count
- [x] Repository contributor count
- [x] Repository branch count
- [x] Repository branch time
- [x] Repository branch commit aheadby count
- [x] Repository branch commit behindby count
- [x] Repository branch line addition count
- [x] Repository branch line deletion count
- [x] Repository pull request open time
- [x] Repository pull request time to merge
- [x] Repository pull request time to approval
- [x] Repository pull request count | stores an attribute of `pull_request.state` equal to `open` or `merged`
- [x] Repository CVE count | stores an attribute of `cve.severity` equal to `low`, `medium`, `high`, or `critical`

## GitLab Metrics

The current metrics available via scraping from GitLab are:

- [x] Repository count
- [x] Repository contributor count
- [x] Repository branch count
- [x] Repository branch time
- [x] Repository branch commit aheadby count
- [x] Repository branch commit behindby count
- [x] Repository branch line addition count
- [x] Repository branch line deletion count
- [x] Repository pull request open time
- [x] Repository pull request time to merge
- [x] Repository pull request time to approval
- [x] Repository pull request count | stores an attribute of `pull_request.state` equal to `open` or `merged`
- [ ] Repository CVE count | stores an attribute of `cve.severity` equal to `low`, `medium`, `high`, or `critical`

### Updating tests

After using `make gen` you may find your tests failing. This could be due to the
`expected_happy_path.yaml` missing some of the changes from your code, or being
out of order.

You can resolve this manually by updating the file, or by regenerating it by
uncommenting the lines starting with `//golden.WriteMetrics` in your test files,
and rerunning the unit tests. Comment the lines out again and commit the new
changes.
